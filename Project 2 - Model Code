import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline


data = pd.read_csv("C:\\Users\\lexiw\\OneDrive\\Desktop\\USA_convid 19_vaccines_2023 (4).csv")

 # Preprocessing data
data = data.dropna()
X = data[['STATE', 'DOSES DISTRIBUTED PER 100K POP', 'DEATHS PER 100K POP', 'YEAR']]
y = data['POLITICAL AFFILIATION']
categorical_features = ['STATE']
numerical_features = ['DOSES DISTRIBUTED PER 100K POP', 'DEATHS PER 100K POP', 'YEAR']

# Preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('num', 'passthrough', numerical_features)
    ],
    remainder='passthrough'
)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest model and fit
rf_model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])
rf_model.fit(X_train, y_train)

# Make predictions
train_predictions = rf_model.predict(X_train)
test_predictions = rf_model.predict(X_test)

# Metrics
train_accuracy = accuracy_score(y_train, train_predictions)
test_accuracy = accuracy_score(y_test, test_predictions)
precision = precision_score(y_test, test_predictions, average='weighted')
recall = recall_score(y_test, test_predictions, average='weighted')
f1 = f1_score(y_test, test_predictions, average='weighted')

# Results
print("Model: Random Forest")
print(f"Train Accuracy: {train_accuracy}")
print(f"Test Accuracy: {test_accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")




#Model: Random Forest
#Train Accuracy: 1.0
#Test Accuracy: 0.7
#Precision: 0.8800000000000001
#Recall: 0.7
#F1 Score: 0.7296703296703297
